三、数据源
数据源可以通过StreamExecutionEnvironment.addSource(sourceFunction)来创建数据源。你可以使用Flink提供的source方法，也可以通过实现SourceFunction来编写自定义的非并行数据源，也可以通过实现ParallelSourceFunction接口或继承RichParallelSourceFunction来编写自定义并行数据源。

以下是几个预定义的数据流源，可以通过StreamExecutionEnvironment来访问：

1.    基于文件的：

·        readTextFile(path) / TextInputFormat - 以行读取方式读文件并返回字符串

·        readFile(path) / 任意输入格式 - 按用输入格式的描述读取文件

·        readFileStream - 创建一个stream，在文件有改动时追加element

2.    基于Socket的：

·        socketTextStream - 从socket读取，element可以通过分割符来分开

3.    基于Collection的：

·        fromCollection(Collection) - 从Java.util.Collection创建一个数据流。collection中所有的element都必须是同一类型的。

·        fromCollection(Iterator, Class) - 从一个迭代器中创建一个数据流。class参数明确了迭代器返回的element的类型。

·        fromElement(T …) - 从一个给定的对象序列创建一个数据流。所有对象都必须是同一类型的。

·        fromParallelCollection(SplittableIterator, Class) - 从一个迭代器中创建一个并行数据流。class参数明确了迭代器返回的element的类型。

·        generateSequence(from, to) - 从一个给定区间中生成一个并行数字序列。

4.    自定义：

·        addSource - 附上一个新的source方法。例如，通过调用addSource(new FlinkKafkaConsumer08<>(…))来从Apache Kafka读取数据，更多信息见于connector：https://ci.apache.org/projects/flink/flink-docs-release-1.0/apis/streaming/connectors/